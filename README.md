
ğŸ§  RAG-Powered Chatbot with LangChain & Streamlit
Welcome to your Retrieval-Augmented Generation (RAG) chatbot! This project leverages LangChain, Streamlit, and Groq to create an intelligent assistant that can answer questions based on the content of a PDF document.

ğŸš€ Features
Retrieval-Augmented Generation (RAG): Combines LLM reasoning with document retrieval for accurate, up-to-date answers.

LangChain Integration: Modular, extensible, and easy to adapt to new data sources or models.

PDF Knowledge Base: Upload a PDF and ask questions about its contents.

Streamlit UI: Clean, interactive chat interface for seamless user experience.

Groq LLM Support: Fast, efficient inference for real-time conversation.

ğŸ“¦ Requirements
Python 3.8+
pipenv
A Groq API Key

ğŸ”§ Installation
Clone the repository:
bash
git clone https://github.com/yourusername/your-repo-name.git
cd your-repo-name
Install dependencies with pipenv:

bash
pipenv install
pipenv shell
Set your Groq API key:

Create a .env file in the project root

â–¶ï¸ Usage
Run the chatbot with Streamlit:

streamlit run ph1.py
Open the provided local URL in your browser to interact with the chatbot.

ğŸ“ How It Works
Document Loading: The app loads and splits your PDF into chunks.
Vector Store: Embeddings are created using HuggingFace models and stored for fast retrieval.
RAG Pipeline: User questions are matched to relevant document chunks, and the LLM (via Groq) generates answers using both the retrieved context and its own knowledge.
Chat History: All interactions are displayed for context and continuity.

ğŸ“‚ Project Structure
text
â”œâ”€â”€ ph1.py                # Main Streamlit chatbot app
â”œâ”€â”€ reflexion.pdf         # Your knowledge base PDF
â”œâ”€â”€ Pipfile               # pipenv dependency file
â”œâ”€â”€ Pipfile.lock
â”œâ”€â”€ .env                  # (optional) API keys and secrets
â””â”€â”€ README.md
